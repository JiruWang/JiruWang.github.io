<!DOCTYPE html>
<html lang="en">
<head><!-- hexo injector head_begin start -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\(","\)"] ],
        displayMath: [ ['$$','$$'], ["\[","\]"] ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
    </script>
    <!-- hexo injector head_begin end -->
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 8.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"jiruwang.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.25.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="ü§ó Model Weights | üöÄ Quick Start | ‚öôÔ∏è Installation Guide | üöß Post-Training       üéâ Introduction   Architecture Development: Implementing a high-performance MoE architecture plugin for decod">
<meta property="og:type" content="article">
<meta property="og:title" content="Falcon-MoE:Building Mixture-of-Experts from Falcon-H1 with Expert-aware GRPO Post-Tuning on math reasoning tasks">
<meta property="og:url" content="https://jiruwang.github.io/0205/10/30/README/index.html">
<meta property="og:site_name" content="Jiru&#39;s Blog">
<meta property="og:description" content="ü§ó Model Weights | üöÄ Quick Start | ‚öôÔ∏è Installation Guide | üöß Post-Training       üéâ Introduction   Architecture Development: Implementing a high-performance MoE architecture plugin for decod">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://jiruwang.github.io/images/router.png">
<meta property="article:published_time" content="0205-10-30T14:30:00.000Z">
<meta property="article:modified_time" content="2025-11-03T12:55:20.332Z">
<meta property="article:author" content="jiru">
<meta property="article:tag" content="Falcon">
<meta property="article:tag" content="GRPO">
<meta property="article:tag" content="Math-Reasoning">
<meta property="article:tag" content="MoE">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jiruwang.github.io/images/router.png">


<link rel="canonical" href="https://jiruwang.github.io/0205/10/30/README/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://jiruwang.github.io/0205/10/30/README/","path":"0205/10/30/README/","title":"Falcon-MoE:Building Mixture-of-Experts from Falcon-H1 with Expert-aware GRPO Post-Tuning on math reasoning tasks"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Falcon-MoE:Building Mixture-of-Experts from Falcon-H1 with Expert-aware GRPO Post-Tuning on math reasoning tasks | Jiru's Blog</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"single_dollars":true,"enable":true,"mhchem":true,"cdn":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS-MML_HTMLorMML","tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <!-- hexo injector head_end end --><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Jiru's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#moe"><span class="nav-number">1.</span> <span class="nav-text">üéâ Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#features"><span class="nav-number">2.</span> <span class="nav-text">üî• Features</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#quick-start"><span class="nav-number">3.</span> <span class="nav-text">üöÄ QuickStart</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#installation"><span class="nav-number">4.</span> <span class="nav-text">‚öôÔ∏è Installation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#performance"><span class="nav-number">5.</span> <span class="nav-text">üìä Model Performance</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Post-Training"><span class="nav-number">6.</span> <span class="nav-text">üöß  Post-Training</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">jiru</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">2</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://jiruwang.github.io/0205/10/30/README/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="jiru">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiru's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Falcon-MoE:Building Mixture-of-Experts from Falcon-H1 with Expert-aware GRPO Post-Tuning on math reasoning tasks | Jiru's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Falcon-MoE:Building Mixture-of-Experts from Falcon-H1 with Expert-aware GRPO Post-Tuning on math reasoning tasks
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 0205-10-30 14:30:00" itemprop="dateCreated datePublished" datetime="0205-10-30T14:30:00+00:00">0205-10-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-11-03 12:55:20" itemprop="dateModified" datetime="2025-11-03T12:55:20+00:00">2025-11-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Openrlhf/" itemprop="url" rel="index"><span itemprop="name">Openrlhf</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><div align="center">
  <div>
    <a href="https://huggingface.co/wmere/models" target="_blank">ü§ó Model Weights</a> | <a href="#quick-start">üöÄ Quick Start</a> | <a href="#installation">‚öôÔ∏è Installation Guide</a> | <a href="#Post-Training">üöß Post-Training</a>
  </div>
</div>


<h2 id="moe">üéâ Introduction</h2>

<ol>
<li><strong>Architecture Development</strong>: Implementing a high-performance MoE architecture plugin for decoder-only models.</li>
<li><strong>Training Analysis</strong>: Conducting a detailed analysis of expert and router behavior to identify key bottlenecks and underlying issues during GRPO training.</li>
<li><strong>Algorithm Innovation</strong>: Designing a novel Expert-aware GRPO Post-Tuning algorithm to optimize MoE models efficiently.</li>
</ol>
<h2 id="features">üî• Features</h2>

<ol>
<li><strong>MoE architecture</strong>: class FalconH1MoEForCausalLM is implemented for transformers and VLLM.</li>
<li><strong>Router Dump</strong>: User can save routers‚Äô weight and gradient during training process for analysis purpose by setting ‚Äìhook True, ‚Äìdump_dir  ./</li>
</ol>
<h2 id="quick-start">üöÄ QuickStart</h2>

<p>huggingface: </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># python&gt;=3.12</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> openrlhf.moe_utils <span class="keyword">import</span> FalconH1MoEForCausalLM</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line">model_dir = <span class="string">"wmere/falcon-h1-0.5b-moe"</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line">model = FalconH1MoEForCausalLM.from_pretrained(model_dir, torch_dtype=torch.bfloat16, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">model.to(<span class="string">"cuda:6"</span>)</span><br><span class="line"></span><br><span class="line">input_text = <span class="string">"Solve the following mathematical problem step by step. Please reason carefully and put your final answer within \\boxed{}. Problem: A library cabinet houses five ancient scrolls. The first scroll is 4080 years old. If each scroll is older than the last by half as many years as the last scroll‚Äôs age, how old is the fifth scroll? Step by step reasoning: "</span></span><br><span class="line">inputs = tokenizer(input_text, return_tensors=<span class="string">"pt"</span>)</span><br><span class="line">inputs = inputs.to(<span class="string">"cuda:6"</span>)</span><br><span class="line"></span><br><span class="line">pred = model.generate(**inputs, max_length=<span class="number">2048</span>, temperature=<span class="number">0.0</span>)</span><br><span class="line"><span class="built_in">print</span>(tokenizer.decode(pred.cpu()[<span class="number">0</span>], skip_special_tokens=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure>
<p>vllm:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> vllm <span class="keyword">import</span> LLM, SamplingParams</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> math_verify <span class="keyword">import</span> parse</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">model_path = <span class="string">"wmere/falcon-h1-0.5b-moe"</span></span><br><span class="line">sampling_params = SamplingParams(temperature=<span class="number">0.8</span>, max_tokens=<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line">dataset = load_dataset(<span class="string">"gsm8k"</span>, <span class="string">"main"</span>)</span><br><span class="line">test_set = dataset[<span class="string">'test'</span>].shuffle(seed=<span class="number">42</span>).select(<span class="built_in">range</span>(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">model = LLM(model=model_path,enforce_eager=<span class="literal">True</span>, max_model_len=<span class="number">2048</span>, gpu_memory_utilization=<span class="number">0.8</span>,swap_space=<span class="number">2</span>)</span><br><span class="line">prompts = [test_set[i][<span class="string">'question'</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(test_set))]</span><br><span class="line">output = model.generate(prompts, sampling_params)</span><br><span class="line"><span class="built_in">print</span>(output[<span class="number">0</span>].text)</span><br></pre></td></tr></table></figure>
<h2 id="installation">‚öôÔ∏è Installation</h2>
follow the guide from openrlhf: https://github.com/OpenRLHF/OpenRLHF?tab=readme-ov-file#installation

<h2 id="performance">üìä Model Performance</h2>
setting: openrlhf/moe_utils/gsm8k.yaml

<table>
<thead>
<tr>
<th align="left">Model</th>
<th align="left">GSM8K</th>
</tr>
</thead>
<tbody><tr>
<td align="left">FalconH1-base-0.5B</td>
<td align="left">0.60</td>
</tr>
<tr>
<td align="left">FalconH1-base-3B</td>
<td align="left">0.67</td>
</tr>
<tr>
<td align="left">FalconH1-base-MoE-0.5B(2/4)</td>
<td align="left">0.65</td>
</tr>
</tbody></table>
<img width="600" height="400" alt="image" src="/images/router.png">
https://wandb.ai/wmere39-uni/openrlhf_train_ppo/panel/nhe19qxdy?xAxisMin=0   


<h2 id="Post-Training">üöß  Post-Training</h2>
GRPO training falcon-moe-0.5 using a filtered gsm8k dataset:


<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">ray start</span><br><span class="line">ray job submit --address="http://127.0.0.1:8267" \</span><br><span class="line">   --runtime-env-json='{"working_dir": "MoE-Tuning"}' \</span><br><span class="line">   -- python3 -m openrlhf.cli.train_ppo_ray \</span><br><span class="line">    --ref_num_nodes 1 \</span><br><span class="line">    --ref_num_gpus_per_node 1 \</span><br><span class="line">    --actor_num_nodes 1 \</span><br><span class="line">    --actor_num_gpus_per_node 2 \</span><br><span class="line">    --vllm_num_engines 1 \</span><br><span class="line">    --vllm_tensor_parallel_size 1 \</span><br><span class="line">    --init_kl_coef 1e-3 \</span><br><span class="line">    --vllm_gpu_memory_utilization 0.6 \</span><br><span class="line">    --gamma 1.0 \</span><br><span class="line">    --use_kl_loss \</span><br><span class="line">    --enforce_eager \</span><br><span class="line">    --kl_estimator k3 \</span><br><span class="line">    --advantage_estimator group_norm \</span><br><span class="line">    --pretrain 'wmere/falcon-h1-0.5b-moe' \</span><br><span class="line">    --remote_rm_url openrlhf/trainer/ppo_utils/hard_reward_label.py \</span><br><span class="line">    --eval_n_samples_per_prompt 1 \</span><br><span class="line">    --ckpt_path /home/jiru/save_falcon_0_5_moe \</span><br><span class="line">    --save_steps 1000000000 \</span><br><span class="line">    --micro_train_batch_size 1 \</span><br><span class="line">    --train_batch_size 4 \</span><br><span class="line">    --micro_rollout_batch_size 1 \</span><br><span class="line">    --rollout_batch_size 4 \</span><br><span class="line">    --n_samples_per_prompt 2 \</span><br><span class="line">    --max_epochs 1 \</span><br><span class="line">    --num_episodes 10 \</span><br><span class="line">    --label_key answer \</span><br><span class="line">    --prompt_max_len 1024 \</span><br><span class="line">    --generate_max_len 1024 \</span><br><span class="line">    --zero_stage 2 \</span><br><span class="line">    --bf16 \</span><br><span class="line">    --eval_steps 1 \</span><br><span class="line">    --actor_learning_rate 5e-1 \</span><br><span class="line">    --critic_learning_rate 9e-6 \</span><br><span class="line">    --init_kl_coef 0.01 \</span><br><span class="line">    --prompt_data data/train_base.json \</span><br><span class="line">    --input_key input \</span><br><span class="line">    --max_samples 10000000 \</span><br><span class="line">    --packing_samples \</span><br><span class="line">    --normalize_reward \</span><br><span class="line">    --adam_offload \</span><br><span class="line">    --vllm_sync_backend nccl \</span><br><span class="line">    --gradient_checkpointing \</span><br><span class="line">   --use_wandb  API KEY \</span><br></pre></td></tr></table></figure>

<p>If you want save router‚Äôs behavor, </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> --dump_step 10 \</span><br><span class="line">--hook True \</span><br><span class="line"> --dump_dir /home/jiru/save_falcon_0_5_moe/dump_moe \</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Falcon/" rel="tag"># Falcon</a>
              <a href="/tags/MoE/" rel="tag"># MoE</a>
              <a href="/tags/Math-Reasoning/" rel="tag"># Math-Reasoning</a>
              <a href="/tags/GRPO/" rel="tag"># GRPO</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
            </div>
            <div class="post-nav-item">
                <a href="/2024/10/30/OpenRLHF-PPO-GRPO/" rel="next" title="GRPO in OpenRLHF">
                  GRPO in OpenRLHF <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">jiru</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
